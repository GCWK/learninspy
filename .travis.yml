language: python

addons:
  apt:
    packages:
    - libblas-dev
    - liblapack-dev
    - gfortran

virtualenv:
  system_site_packages: true

before_install:
  - pip install -U pip

install:
  - pip install -r requirements.txt
  - "sudo rm -rf /dev/shm && sudo ln -s /run/shm /dev/shm"

matrix:
  include:
    - jdk: openjdk7
      python: 2.7
      env: >
        SPARK_VERSION='1.6.0'
        HADOOP_VERSION='2.4'
        SPARK_HOME=/tmp/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION
        PYTHONPATH=$SPARK_HOME/python/:$SPARK_HOME/python/lib/py4j-0.9-src.zip:$PYTHONPATH

before_script:
  # Download Spark
  - curl http://d3kbcqa49mib13.cloudfront.net/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz --output /tmp/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz	
  - tar -xvzf /tmp/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz
 
script: 
  - echo $PYTHONPATH
  - sh run_tests.sh

notifications:
  email:
    on_success: always
    on_failure: never

